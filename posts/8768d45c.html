<!DOCTYPE html><html lang="zh"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="canonical" href="https://babybluue.github.io/posts/8768d45c"><link rel="manifest" href="/manifest.webmanifest"><link rel="apple-touch-icon" sizes="192x192" href="/images/appleicon"><link rel="apple-touch-startup-image" media="(device-width: 750px) and (device-height:1334px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)" href="/images/launch"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="apple-mobile-web-app-title" content="babyblue"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1f1f1f"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#fff"><meta name="color-scheme" content="light dark"><link rel="icon" href="/images/favicon.ico"><meta name="description" content="Scrapy is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival. "><meta name="keywords" content="blog,博客,程序员,记录,学习,网站 "><title>Scrapy初体验</title><link rel="stylesheet" href="/style/style.css"><link rel="stylesheet" href="/style/highlight.css" media="none" onload='this.media="all"'><link rel="stylesheet" href="/style/fancybox.css" media="none" onload='this.media="all"'><script type="text/javascript">var currentPath=window.location.pathname,targetUrl="https://didmax.pages.dev";window.location.href=targetUrl+currentPath</script><script>localStorage.theme&&document.documentElement.setAttribute("data-theme",localStorage.theme)</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-TMJ0G5Z2NR"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-TMJ0G5Z2NR")</script><script>document.onreadystatechange=()=>{const t=document.querySelector(".loading-bar");700<document.body.clientWidth&&(t.style.background="#91C4E2","interactive"==document.readyState&&(t.style.transition="width 1.4s ease-in-out",t.style.width="67%"),"complete"==document.readyState&&(t.style.transition="width 0.3s ease-in-out",t.style.width="100%",setTimeout(()=>{t.setAttribute("style","transition:width 0s;width:0;background:''")},500)))}</script><meta name="generator" content="Hexo 5.4.2"></head><body class="scroll-bar"><div class="loading-bar"></div><div class="progress-bar"></div><main><header><nav><ul class="nav-button"><li></li><li></li><li></li></ul><div class="nav-bar"><ul><span class="close-button">×</span><div class="nav-avatar"><a href="/" aria-label="index"><img src="/images/avatar.png" class="avatar" alt="avatar"></a></div><li><a href="/archives/">Archive</a></li><li><a href="/notes/">Notes</a></li><li><a href="/articles/">Articles</a></li><li><a href="mailto:kerrismith19786@gmail.com" rel="external nofollow noreferrer">Contact</a></li></ul></div></nav></header><div class="post-main"><article><div class="post-card"><div class="header-title">Scrapy初体验</div><div class="header-info"><span>2021.04.25 Sun</span></div><div class="card-content"><blockquote><p>Scrapy is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival.</p></blockquote><span id="more"></span><h4 id="设置-python-虚拟环境"><a class="markdownIt-Anchor" href="#设置-python-虚拟环境"></a> 设置 python 虚拟环境</h4><p>为了避免安装第三方依赖时总是安装在全局而导致不同项目之间的冲突，python 可以使用虚拟环境的方式满足不同应用的需求。</p><blockquote><p>The solution for this problem is to create a virtual environment, a self-contained directory tree that contains a Python installation for a particular version of Python, plus a number of additional packages.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python -m venv virtual-env<br></code></pre></td></tr></table></figure><p>命令会创建一个 virtual-enviroment 的文件夹，里面包含 python 编译器、标准库和其他一些文件,其中在 Scripts 文件夹下包含激活虚拟环境的执行文件。</p><ul><li>activate.bat 在 windows cmd 里运行 <code>virtual-env\Scripts\activate.bat</code></li><li>Activate.PS1 在 windows pwd 里运行 <code>virtual-env\Scripts\Activate.PS1</code></li><li>activate 在 Unix 和 MacOs 里运行 <code>source virtual-env/bin/activate</code></li><li>deactivate.bat 取消虚拟环境</li></ul><p>后面安装 scrapy 等都会安装在虚拟环境里</p><h4 id="scrapy-开始项目"><a class="markdownIt-Anchor" href="#scrapy-开始项目"></a> Scrapy 开始项目</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">scrapy startproject tutorial <span class="hljs-built_in">test</span><br></code></pre></td></tr></table></figure><p>在 test 文件夹下创建名为 tutorial 的 Scrapy project，test 文件夹下有以下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">scrapy.cfg            # deploy configuration file<br>tutorial/             # project&#x27;s Python module, you&#x27;ll import your code from here<br>    __init__.py<br>    items.py          # project items definition file<br>    middlewares.py    # project middlewares file<br>    pipelines.py      # project pipelines file<br>    settings.py       # project settings file<br>    spiders/          # a directory where you&#x27;ll later put your spiders<br>        __init__.py<br></code></pre></td></tr></table></figure><p>在 spiders 目录下写自己的爬虫文件，在 <a target="_blank" rel="noopener external nofollow noreferrer" href="http://setting.py">setting.py</a> 里可以配置请求头等一些内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#spiders/douban250_spider.py</span><br><span class="hljs-keyword">import</span> scrapy<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DoubanSpider</span>(scrapy.Spider):<br>    name = <span class="hljs-string">&#x27;douban&#x27;</span><br>    start_urls = [<br>        <span class="hljs-string">&#x27;https://movie.douban.com/top250&#x27;</span>]<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>(<span class="hljs-params">self, response</span>):<br>        <span class="hljs-keyword">for</span> title <span class="hljs-keyword">in</span> response.css(<span class="hljs-string">&#x27;div.hd&#x27;</span>):<br>            <span class="hljs-keyword">yield</span>&#123;<br>                <span class="hljs-string">&#x27;title&#x27;</span>:title.css(<span class="hljs-string">&#x27;span.title::text&#x27;</span>).get()<br>            &#125;<br>        <span class="hljs-keyword">yield</span> <span class="hljs-keyword">from</span> response.follow_all(css=<span class="hljs-string">&#x27;span.next a&#x27;</span>,callback=self.parse)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#setting.py</span><br>DEFAULT_REQUEST_HEADERS = &#123;<br>    <span class="hljs-string">&#x27;Accept&#x27;</span>: <span class="hljs-string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9&#x27;</span>,<br>    <span class="hljs-string">&#x27;Accept-Encoding&#x27;</span>: <span class="hljs-string">&#x27;gzip, deflate&#x27;</span>,<br>    <span class="hljs-string">&#x27;Accept-Language&#x27;</span>: <span class="hljs-string">&#x27;zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7&#x27;</span>,<br>    <span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;text/html; charset=utf-8&#x27;</span>,<br>    <span class="hljs-string">&#x27;Cache-Control&#x27;</span>: <span class="hljs-string">&#x27;max-age=0&#x27;</span>,<br>    <span class="hljs-string">&#x27;Connection&#x27;</span>: <span class="hljs-string">&#x27;keep-alive&#x27;</span>,<br>    <span class="hljs-string">&#x27;User-Agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.128 Safari/537.36&#x27;</span><br>&#125;<br>FEED_EXPORT_ENCODING = <span class="hljs-string">&quot;UTF-8&quot;</span> <span class="hljs-comment">#设置导出编码格式</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">scrapy crawl douabn -O douban-250.json <span class="hljs-comment">#执行并导出结果为 json 文件</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">scrapy shell <span class="hljs-string">&quot;https://movie.douban.com/top250&quot;</span> <span class="hljs-comment">#在命令行里测试请求的页面信息</span><br></code></pre></td></tr></table></figure><hr><p>参考链接：<br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://docs.scrapy.org/en/latest/intro/tutorial.html">Scrapy 文档</a></p></div><div class="post-tags"><a href="/tags/Python/">Python</a></div></div></article><div class="post-pagination"><div class="prev-page"><a href="/posts/2f178655" title="你在教我做人?">你在教我做人?</a></div><div class="next-page"><a href="/posts/5b583158" title="Angular模块module ">Angular模块module</a></div></div></div><svg t="1673947892053" class="top" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="9313" width="45" height="45"><path d="M535.12 442.432v210.016a16 16 0 0 1-16 16h-16.16a16 16 0 0 1-16-16V440.208l-32.88 32.864a16 16 0 0 1-11.312 4.688h-28.304a14.464 14.464 0 0 1-10.24-24.688l97.824-97.808a11.136 11.136 0 0 1 15.744 0l97.808 97.808a14.464 14.464 0 0 1-10.24 24.688h-28.288a16 16 0 0 1-11.312-4.688l-30.64-30.64zM512 800c159.056 0 288-128.944 288-288s-128.944-288-288-288-288 128.944-288 288 128.944 288 288 288z m0 48c-185.568 0-336-150.432-336-336s150.432-336 336-336 336 150.432 336 336-150.432 336-336 336z" p-id="9314"></path></svg><div class="tip disappear"><p>检测到页面内容有更新，是否刷新页面 <span class="positive-btn">是</span><span class="negative-btn">否</span></p></div></main><script src="/scripts/script.js" async></script><script async type="module">import{Fancybox}from"/scripts/fancybox.esm.js";Fancybox.bind('[data-fancybox="gallery"]',{Toolbar:{display:["fullscreen","download","close"]}})</script></body></html>